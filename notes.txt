Trying to think up a good separator for .many files that never appears in any language's syntax.

According to https://www.wired.com/2013/08/the-rarity-of-the-ampersand/
*Character Frequency*: SPC e t a o i n s r h l d c u m f g p y w ENT b , . v k - " _ ' x ) ( ; 0 &nbsp;j 1 q = 2 : z / * ! ? $ 3 5 > { } 4 9 [ ] 8 6 7  + | & < % @ # ^ ` ~
*Punctuation Frequency*: , . - " _ ' ) ( ; = : / * ! ? $ > { } [ ]  + | & < % @ # ^ ` ~

so `~^@# seem good candidates

~~~ feels to simple, a language that uses ~ as a comment might have ~~~THING~~~ in it


~!@ appears here https://github.com/ICGog/MapReduce-Thorn/blob/master/lib/fisher/testcase/eval/071-json/071a.th
~!@eq(jsonParse('"\\u0041"'), 'A')@!~  ;

a few languages use @ or ~ for comments https://rosettacode.org/wiki/Comments

@~~ seems like it'd work, "spring" operator
@~~NAME~~@

using chars forbidden in filenames might be a good idea
on Linux that's just /
on windows there's way more but stick to /

\@/NAME\@/ yay operators
look worse and harder to type

also a good idea to start it with a character that doesn't usually start lines
so none of / # @

maybe then
~~| PYTHON |~~
~~~| PYTHON |~~~
~~~| py |~~~

I like "~~~| " on both sides since it looks nice and adds 10 chars to the line, nice even number
no real google github search results for it, good

think I want to be lenient with case and abbreviations
py PYTHON PY python Python all fine

but also is ~ on most keyboards? https://superuser.com/questions/667622/italian-keyboard-entering-tilde-and-backtick-characters-without-changin

ยง could be another option but ehh, way too hard to type


# TODO
# detect command errors like "python" unrecognized
# way to comment out a snippet !~~~|?
# argv passthrough - overridable - allow multiline for \ continuation becaus
# shared stdin - overridable - from file even?
# add other 7 languages to languages.json
# number the runs
# verbose for unknown langs and other errors?
# polyglots should be testable
# could be a pip package manyfile
# option to ignore empty lines? place for options in general - like to show when language unknown
# ~~~| skip blank lines |~~~ - also contextual and overridable
# but would need two skip and no skip, tidy, untidy - maybe compact, condensed, flatten uncondensed

# stdin, argv, condensed, uncondensed
# actually rethinking with @@@ $$$ syntax
# could even allow language "sets" in languages.json but no

# forget aboput othernames? - maybe
# so dict is "Languagename": "command $file $argv"
# forget about version too, now
# also just have strip_blank_lines true by default
# and all: "All"

# lists for stdin, argv


possible errors
- language not known
- sep before nonsep
- command not known? don't crash


                # print(section)
                # print(repr(section))
                # TODO NEXT
                # - combine the yielded sections into runnable queries (run JIT, all arvg variants x all stdin variants, for each lang in |list|)
                # - remember languages from last connected CODE in CODE SEP
                # - error if there's a separator that doesn't match context
                # HANG ON - why even have multiple separators? it does tell the type but does that matter?
                # could refactor with additional SEP in enum and combine as needed
                # then no error to check (unless they come first - but could just ignore those)
                # problem is what is the syntax?
                # decide this, but either way think about strict mode for errors? json bool
                # on reflection, kinda ok that the seps are diff

json being (potentially) unordered may be a good reason to use a list
but then you still need a dict for lookup...


import json
from typing import Any, List, Dict, DefaultDict, Optional, TextIO, Iterator, cast
from enum import Enum, auto
from collections import defaultdict

STARTS = CODE_START, ARGV_START, STDIN_START = '~~~|', '@@@|', '$$$|'
ENDS = CODE_END, ARGV_END, STDIN_END = '|~~~', '|@@@', '|$$$'
SEPS = CODE_SEP, ARGV_SEP, STDIN_SEP = '~~~|~~~', '@@@|@@@', '$$$|$$$'
LANGUAGE_DIVIDER, COMMENT_PREFIX = '|', '!'

ALL_KEY = 'all'
STRIP_BLANK_LINES_KEY = 'strip_blank_lines'
LANGUAGES_KEY, NAME_KEY, COMMAND_KEY = 'languages', 'name', 'command'
FILE_PLACEHOLDER, ARGV_PLACEHOLDER = '$file', '$argv'
FILE_MISSING_APPEND = f' {FILE_PLACEHOLDER}'
ARGV_MISSING_APPEND = f' {ARGV_PLACEHOLDER}'

DEFAULT_LANGUAGES_JSON = 'default_languages.json'
BACKUP_LANGUAGES_JSON = {
    ALL_KEY: "All",
    LANGUAGES_KEY: [],
    STRIP_BLANK_LINES_KEY: True
}


def removeprefix(string: str, prefix: str) -> str:
    return string[len(prefix):] if string.startswith(prefix) else string


def removesuffix(string: str, suffix: str) -> str:
    return string[:-len(suffix)] if string.endswith(suffix) else string


class SectionType(Enum):
    CODE = auto()
    ARGV = auto()
    STDIN = auto()


class Section:
    def __init__(self, header: str, content: str, line_number: int = 0) -> None:
        self.header = header.rstrip()
        self.content = content  # todo strip blank lines here
        self.line_number = line_number
        self.commented = self.header.startswith(COMMENT_PREFIX)

        header = removeprefix(self.header, COMMENT_PREFIX)
        self.is_sep = header in SEPS

        if header == CODE_SEP or header.startswith(CODE_START):
            self.type, start, end = SectionType.CODE, CODE_START, CODE_END
        elif header == ARGV_SEP or header.startswith(ARGV_START):
            self.type, start, end = SectionType.ARGV, ARGV_START, ARGV_END
        elif header == STDIN_SEP or header.startswith(STDIN_START):
            self.type, start, end = SectionType.STDIN, STDIN_START, STDIN_END

        if self.is_sep:
            self.languages = []
        else:
            header = removesuffix(removeprefix(header, start), end)
            # TODO replace ALL up here, and maybe only do unique and warn about duplicates? but then need json, and to check for all in names already, do that in json parser
            self.languages = [lang.strip().lower() for lang in header.split(LANGUAGE_DIVIDER)]

    def __str__(self) -> str:
        return f"{self.header}\n{self.content}"

    def __repr__(self) -> str:
        return f"{'//' if self.commented else ''}{self.type.name} " \
               f"{'SEP' if self.is_sep else self.languages} line {self.line_number}"

    @staticmethod
    def line_is_header(line: str) -> bool:
        line = removeprefix(line.rstrip(), COMMENT_PREFIX)
        return line in SEPS or \
            any(line.startswith(start) and line.endswith(end) for start, end in zip(STARTS, ENDS))


def load_languages_json(languages_json: str) -> Any:
    try:
        with open(languages_json) as file:
            return json.load(file)
    except (OSError, json.JSONDecodeError):
        return BACKUP_LANGUAGES_JSON


def section_iterator(file: TextIO) -> Iterator[Section]:
    header: Optional[str] = None
    header_line_number = 0
    section_lines: List[str] = []
    for line_number, line in enumerate(file, 1):
        if Section.line_is_header(line):
            if header is not None:
                yield Section(header, ''.join(section_lines), header_line_number)
            header = line
            header_line_number = line_number
            section_lines = []
        else:
            section_lines.append(line)

    if header is not None:
        yield Section(header, ''.join(section_lines), header_line_number)


def runone(language: str, command: str, code: str, argv: str, stdin: str) -> None:
    print(f'Running {language}.')


# TODO NOW - refactor json to use list of langs, the redo map to objects, then fix all, then fix runone

def runall(languages: List[str], argvs: DefaultDict[str, List[str]], stdins: DefaultDict[str, List[str]], code: str) -> None:
    for lang in languages:
    if lang not in languages_lower:
        print(f'Unknown language {lang}. Be sure to add it to languages.json')
        continue
    # TODO what about ALL??
    for argv in argvs[lang] if argvs[lang] else ['']:
        for stdin in stdins[lang] if stdins[lang] else ['']:
            language_obj = language_dict[lang]
            runone(language_obj[NAME_KEY], language_obj[COMMAND_KEY],
                   section.content, argv, stdin)


def output_iterator(file, languages_json):
    for section in section_iterator(file):
        if section.commented:
            continue

        if section.is_sep:
            if lead_section is None:  # TODO better/optional error messages
                print(f'Lead section missing. Skipping {repr(section)}')
                continue
            elif lead_section is not None and section.type is not lead_section.type:
                print(f'No matching lead section. Skipping {repr(section)}')
                continue
        else:
            lead_section = section

        if section.type is SectionType.CODE:
            runall(lead_section.languages, )
        elif section.type is SectionType.ARGV:
            update(argvs)
        elif section.type is SectionType.STDIN:
            update(stdins)


# def runsection()


def runmany(many_file: str, languages_json_file: str = DEFAULT_LANGUAGES_JSON) -> None:
    languages_json = load_languages_json(languages_json_file)

    lead_section: Optional[Section] = None
    argvs: DefaultDict[str, List[str]] = defaultdict(list)
    stdins: DefaultDict[str, List[str]] = defaultdict(list)

    def update(argvs_or_stdins: DefaultDict[str, List[str]]) -> None:
        for lang in cast(Section, lead_section).languages:
            if not section.is_sep:
                argvs_or_stdins[lang].clear()
            argvs_or_stdins[lang].append(section.content)

    with open(many_file) as file:
        for output in output_iterator(file, ):
            print(output)

    with open(many_file) as file:
        for section in section_iterator(file):
            if section.commented:
                continue

            if section.is_sep:
                if lead_section is None:  # TODO better/optional error messages
                    print(f'Lead section missing. Skipping {repr(section)}')
                    continue
                elif lead_section is not None and section.type is not lead_section.type:
                    print(f'No matching lead section. Skipping {repr(section)}')
                    continue
            else:
                lead_section = section

            if section.type is SectionType.CODE:
                runall(lead_section.languages, )
            elif section.type is SectionType.ARGV:
                update(argvs)
            elif section.type is SectionType.STDIN:
                update(stdins)


if __name__ == "__main__":
    runmany('test.many')

    # def get_language_commands(language_json_data):
    #     command = language_json_data.get('command')
    #     if command is None:
    #         return {}
    #     names = []
    #     if "name" in language_json_data:
    #         names.append(language_json_data["name"])
    #     names.extend(language_json_data.get("other_names", []))
    #     return {name.strip().lower(): command for name in names}

    # def get_commands_dict(commands_dict):
    #     if commands_dict is None:
    #         with open(DEFAULT_LANGUAGES_JSON) as f:
    #             commands_dict = {}
    #             for language in json.load(f).get("languages", []):
    #                 for name, command in get_language_commands(language).items():
    #                     if name not in commands_dict:
    #                         commands_dict[name] = command
    #     return commands_dict

    # def runone(language, command, snippet):
    #     print(f"{LANG_START} {language} {LANG_END}")
    #     with tempfile.NamedTemporaryFile(mode="w", delete=False) as tmp:
    #         tmp.write(snippet)
    #         tmp_filename = tmp.name
    #     if FILENAME_PLACEHOLDER in command:
    #         command = command.replace(FILENAME_PLACEHOLDER, f'"{tmp_filename}"')
    #     else:
    #         command += f' "{tmp_filename}"'
    #     try:
    #         subprocess.check_call(command)
    #         return True
    #     except subprocess.CalledProcessError:
    #         return False
    #     finally:
    #         os.remove(tmp_filename)

    # def runmany(manyfile, string=False, commands_dict=None):
    #     def tryrun():
    #         nonlocal snippets, runs, successes
    #         if language is not None:
    #             snippets += 1
    #             if language.lower() in commands_dict:
    #                 runs += 1
    #                 if runone(language, commands_dict[language.lower()], ''.join(snippet_lines)):
    #                     successes += 1

    #     snippets, runs, successes = 0, 0, 0
    #     commands_dict = get_commands_dict(commands_dict)

    #     with (io.StringIO if string else open)(manyfile) as f:
    #         language = None
    #         snippet_lines = []
    #         for line in f:
    #             stripped = line.strip()
    #             if stripped.startswith(LANG_START) and stripped.endswith(LANG_END):
    #                 tryrun()
    #                 language = stripped[len(LANG_START):-len(LANG_END)].strip()
    #                 snippet_lines.clear()
    #             elif language is not None:
    #                 snippet_lines.append(line)
    #         tryrun()
    #     print(f"{LANG_START} {snippets} , {runs}, {successes} {LANG_END}")


{
	"all": "All",
	"languages": [
		{
			"name": "Python",
			"command": "python"
		},
		{
			"name": "JavaScript",
			"command": "node"
		},
		{
			"name": "TypeScript",
			"command": "deno"
		}
	],
	"strip_blank_lines": true,
	"strict": "TODO? strict mode?"
}

self.languages = []
        if not self.is_sep:
            header = removesuffix(removeprefix(header, start), end)
            for language in header.split(LANGUAGE_DIVIDER):
                language = normalize_name(language)
                if language == normalize_name(cast(str, DEFAULT_LANGUAGES_JSON[ALL_KEY])):
                    self.languages.extend(all_languages)
                else:
                    self.languages.append(language)

	# TODO NOW - refactor json to use list of langs, the redo map to objects, then fix all, then fix runone

# def runall(languages: List[str], argvs: DefaultDict[str, List[str]], stdins: DefaultDict[str, List[str]], code: str) -> None:
#     for lang in languages:
#     if lang not in languages_lower:
#         print(f'Unknown language {lang}. Be sure to add it to languages.json')
#         continue
#     for argv in argvs[lang] if argvs[lang] else ['']:
#         for stdin in stdins[lang] if stdins[lang] else ['']:
#             language_obj = language_dict[lang]
#             runone(language_obj[NAME_KEY], language_obj[COMMAND_KEY],
#                    section.content, argv, stdin)



Run should look like


@@@| Python (line 9)|@@@
some argv, if any
$$$| Python (line 4) |$$$
some stdin, if any
~~~| Python Output (#3 at line 7) |~~~


@@@| argv at line 9|@@@
some argv, if any
$$$| Python (line 4) |$$$

~~~| Python (#3 at line 8) |~~~

@@@| argv at line 9|@@@

$$$| stdin at line 9|$$$

~~~| Output |~~~

Hello, World!
~~~| JS |~~~
Hello, World!


3. Python Output (line 89)


    def __str__(self) -> str:
        lines = []
        lines.append(f'{CODE_START} {self.language} Output (#{self.number} line {self.code_section.line_number}) {CODE_END}\n')
        if self.argv_section:
            lines.append(f'{ARGV_START} {self.language} (line {self.argv_section.line_number}) {ARGV_END}\n')
            lines.append(self.argv_section.content)
        if self.stdin_section:
            lines.append(f'[{STDIN_START} ]stdin line {self.stdin_section.line_number} {STDIN_END}\n')
            lines.append(self.stdin_section.content)
        # lines.append(f'{CODE_START} {self.language} (#{self.number} line {self.code_section.line_number}) {CODE_END}\n')
        lines.append(str(self.output))

        return ''.join(lines) + '\n\n'